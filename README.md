# ðŸš€ Features

- âœ… **Built from scratch** â€“ No high-level libraries like transformers.
- âœ… **Decoder-Only Transformer** â€“ Similar to GPT-style autoregressive models.
- âœ… **Multi-Head Attention** â€“ Captures complex word relationships.
- âœ… **Masked Self-Attention** â€“ Ensures left-to-right sequence generation.
- âœ… **Pre-Norm Transformer** â€“ Improves training stability.
- âœ… **PyTorch Lightning Integration** â€“ Simplifies training and validation.
